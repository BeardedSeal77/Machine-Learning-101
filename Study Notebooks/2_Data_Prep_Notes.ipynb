{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd77ddf",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "\n",
    "<div>\n",
    "    <img src=\"src/images/dataprep.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "also commonly called **data pre-processing**, is a fundamental step in the machine learning workflow. It's essentially the process of getting the raw data ready for a machine learning or AI model.  Imagine it like cleaning and prepping ingredients before cooking a meal. One wouldn't throw raw, unwashed vegetables straight into a pot when making a stew. Data preparation is essential because it directly impacts the quality and effectiveness of the machine learning model. \"Garbage in, garbage out\" applies here, if you feed your model messy or unorganized data, you'll get unreliable results.\n",
    "\n",
    "There are several important tasks in the data preparation stage, including:\n",
    "\n",
    "-   Data Cleaning: This involves identifying and fixing errors, inconsistencies, and missing values in your data.  For instance, one might need to remove duplicate entries, deal with data outliers, correct typos, or find a way to handle data points where information is absent.\n",
    "\n",
    "-   Data Manipulation: This might involve scaling your data or transforming the data in some way, such as encoding categorical variables. Encoding transforms non-numeric data (like text categories) into a format a machine learning model can understand, often using numerical representations.\n",
    "\n",
    "-   Data Reduction: In some cases, you might have a very large dataset. Data reduction techniques like dimensionality reduction can help you identify the most important features and reduce the size of your data without losing significant information.\n",
    "\n",
    "-   Feature Engineering: While data cleaning and scaling ensures that the data is usable,  feature engineering goes a step further. It's the art of creating new features or transforming existing ones to be more informative for your machine learning model. By crafting informative features, you essentially give your model a richer understanding of the data, leading to more accurate and powerful results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03202261",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "\n",
    "Many machine learning or deep learning algorithms (such as Linear Regression, Logistic Regression, and Artificial Neural Networks) assume that the variable data are normally distributed (i.e. follow a Gaussian distribution) and can perform much better if the data provided to them during modeling are normally distributed.\n",
    "\n",
    "<div>\n",
    "    <img src=\"src/images/rightskew.png\" width=\"600\">\n",
    "</div>\n",
    "\n",
    "Right-skewed Distribution: When the distribution has a long tail towards the right side, then it is known as a right-skewed or positive-skewed distribution. In the right-skewed distribution, the concentration of data points towards the right tail is more than the left tail.\n",
    "\n",
    "<div>\n",
    "    <img src=\"src/images/leftskew.png\" width=\"600\">\n",
    "</div>\n",
    " \n",
    "Left-skewed Distribution: When the distribution has a long tail towards the left side, then it is known as a left-skewed or negative-skewed distribution. In the negative-skewed distribution, the concentration of data points towards the left tail is more than the right tail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89138a",
   "metadata": {},
   "source": [
    "#### Measuring Skewness\n",
    "\n",
    "Skewness measures the lack of symmetry in a distribution.\n",
    "\n",
    "    A perfectly symmetric distribution (like the normal distribution) has a skewness of 0.\n",
    "\n",
    "    If data is skewed right (tail to the right), skewness is positive.\n",
    "\n",
    "    If data is skewed left (tail to the left), skewness is negative.\n",
    "\n",
    "Formula for Skewness Coefficient\n",
    "\n",
    "The sample skewness is given by:\n",
    "\n",
    "<div>\n",
    "    <img src=\"src/images/skeweq.png\" width=\"300\">\n",
    "</div>\n",
    "\n",
    "Where:\n",
    "- n  = number of samples\n",
    "- xi = data value\n",
    "- x¯ = sample mean\n",
    "- s  = sample standard deviation\n",
    "\n",
    "Alternatively, libraries like Pandas and SciPy use\n",
    "\n",
    "`df['feature'].skew()         # from Pandas`\n",
    "\n",
    "`scipy.stats.skew(df['feature'])  # from SciPy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c81a82",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "#T_d4da2 th {\n",
    "  text-align: left;\n",
    "}\n",
    "#T_d4da2_row0_col0, #T_d4da2_row0_col1, #T_d4da2_row1_col0, #T_d4da2_row1_col1, #T_d4da2_row2_col0, #T_d4da2_row2_col1 {\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "<table id=\"T_d4da2\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th class=\"blank level0\" >&nbsp;</th>\n",
    "      <th id=\"T_d4da2_level0_col0\" class=\"col_heading level0 col0\" >Skewness Value</th>\n",
    "      <th id=\"T_d4da2_level0_col1\" class=\"col_heading level0 col1\" >Interpretation</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th id=\"T_d4da2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
    "      <td id=\"T_d4da2_row0_col0\" class=\"data row0 col0\" >≈0</td>\n",
    "      <td id=\"T_d4da2_row0_col1\" class=\"data row0 col1\" >Symmetric (normal)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_d4da2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
    "      <td id=\"T_d4da2_row1_col0\" class=\"data row1 col0\" >>0</td>\n",
    "      <td id=\"T_d4da2_row1_col1\" class=\"data row1 col1\" >Right-skewed (positive skew)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_d4da2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
    "      <td id=\"T_d4da2_row2_col0\" class=\"data row2 col0\" ><0</td>\n",
    "      <td id=\"T_d4da2_row2_col1\" class=\"data row2 col1\" >Left-skewed (negative skew)</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f513b5",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    "#T_d5957 th {\n",
    "  text-align: left;\n",
    "}\n",
    "#T_d5957_row0_col0, #T_d5957_row0_col1, #T_d5957_row1_col0, #T_d5957_row1_col1, #T_d5957_row2_col0, #T_d5957_row2_col1 {\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "<table id=\"T_d5957\">\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th class=\"blank level0\" >&nbsp;</th>\n",
    "      <th id=\"T_d5957_level0_col0\" class=\"col_heading level0 col0\" >Absolute Value</th>\n",
    "      <th id=\"T_d5957_level0_col1\" class=\"col_heading level0 col1\" >Interpretation</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th id=\"T_d5957_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
    "      <td id=\"T_d5957_row0_col0\" class=\"data row0 col0\" >< 0.5</td>\n",
    "      <td id=\"T_d5957_row0_col1\" class=\"data row0 col1\" > \tApproximately symmetric</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_d5957_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
    "      <td id=\"T_d5957_row1_col0\" class=\"data row1 col0\" >0.5 – 1</td>\n",
    "      <td id=\"T_d5957_row1_col1\" class=\"data row1 col1\" >Moderately skewed</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th id=\"T_d5957_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
    "      <td id=\"T_d5957_row2_col0\" class=\"data row2 col0\" >> 1</td>\n",
    "      <td id=\"T_d5957_row2_col1\" class=\"data row2 col1\" > \tHighly skewed</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec46857",
   "metadata": {},
   "source": [
    "Positive/Right Skewed Data\n",
    "\n",
    "One can use simple transformations to \"normalize\" right-skewed data:\n",
    "\n",
    "-   log transformations:\n",
    "    -   np.log(), np.log10 (but this does not deal with zeros in the data)\n",
    "    -   np.log1p(x) = log(x+1) adds 1, but can only be used for positive data,\n",
    "-   square-root transformations: np.sqrt()\n",
    "\n",
    "There are several sklearn library functions for dealing with right-skwed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    \"Method\": [\n",
    "        \"Log1p (Natural log + 1)\",\n",
    "        \"Box-Cox (Scikit-Learn)\",\n",
    "        \"Yeo-Johnson (Scikit-Learn)\",\n",
    "        \"Custom log(x + ε)\",\n",
    "        \"QuantileTransformer\"\n",
    "        ],\n",
    "    \" \tFormula / Tool\": [\n",
    "        \"np.log1p(x) = log(1 + x)\",\n",
    "        \"PowerTransformer(method='box-cox')\",\n",
    "        \"PowerTransformer(method='yeo-johnson')\",\n",
    "        \"np.log(x + 1e-6)\"\n",
    "    ],\n",
    "    \"Handles Zeros?\": [\"yes\", \"yes\", \"yes\"],\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "df.style.set_properties(**{'text-align': 'left'}).set_table_styles(\n",
    "    [{'selector': 'th', 'props': [('text-align', 'left')]}]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
